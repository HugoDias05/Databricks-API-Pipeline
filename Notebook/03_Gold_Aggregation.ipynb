{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d428b2f-4b82-4ca7-867a-a6d3c2457bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 03_Gold_Aggregation.py - Aggregates Silver data for BI and saves to Gold Layer\n",
    "\n",
    "from pyspark.sql.functions import col, count, min\n",
    "\n",
    "# Persistence Configuration (MUST MATCH 01_Bronze and 02_Silver)\n",
    "CATALOG_NAME = \"workspace\" \n",
    "SCHEMA_NAME = \"default\"\n",
    "SILVER_TABLE_NAME = \"omdb_releases_silver\"\n",
    "GOLD_TABLE_NAME = \"omdb_releases_gold\"\n",
    "FULL_SILVER_PATH = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{SILVER_TABLE_NAME}\"\n",
    "FULL_GOLD_PATH = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{GOLD_TABLE_NAME}\"\n",
    "\n",
    "print(f\"--- 1. READING THE SILVER LAYER from: {FULL_SILVER_PATH} ---\")\n",
    "\n",
    "# --- 1. LOAD (READS SILVER) ---\n",
    "# Reads the cleaned data that was persisted by 02_Silver_Transformation.py\n",
    "try:\n",
    "    df_silver = spark.read.table(FULL_SILVER_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not read Silver table '{FULL_SILVER_PATH}'.\")\n",
    "    print(f\"Ensure 02_Silver_Transformation.py ran successfully. Error details: {e}\")\n",
    "    dbutils.notebook.exit(\"Failed to read Silver table.\")\n",
    "\n",
    "\n",
    "print(f\"--- 2. AGGREGATING FOR GOLD (Business KPI) ---\")\n",
    "\n",
    "# --- 2. AGGREGATION (GOLD) ---\n",
    "df_gold = df_silver.groupBy(\"release_year\", \"media_type\") \\\n",
    "                   .agg(\n",
    "                       # Business Metric (KPI): Total number of releases\n",
    "                       count(\"*\").alias(\"total_releases\"),\n",
    "                       \n",
    "                       # Audit Metric: Track when this group was first ingested\n",
    "                       min(\"ingestion_timestamp\").alias(\"first_ingestion_date\")\n",
    "                   ) \\\n",
    "                   .orderBy(col(\"release_year\").desc())\n",
    "\n",
    "print(f\"Gold DataFrame (Datamart) ready with {df_gold.count()} aggregated rows.\")\n",
    "\n",
    "# --- 3. PERSISTENCE (SAVES GOLD) ---\n",
    "# Overwrite the Gold table with the final aggregated datamart\n",
    "df_gold.write \\\n",
    "       .format(\"delta\") \\\n",
    "       .mode(\"overwrite\") \\\n",
    "       .option(\"overwriteSchema\", \"true\") \\\n",
    "       .saveAsTable(FULL_GOLD_PATH)\n",
    "\n",
    "print(f\"Gold Table (Datamart) '{FULL_GOLD_PATH}' saved successfully.\")\n",
    "print(\"The pipeline is complete and the data is ready for BI (SQL Warehouse).\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Gold_Aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
